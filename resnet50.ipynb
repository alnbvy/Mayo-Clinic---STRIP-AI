{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport gc\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\nfrom tensorflow.keras.layers import GlobalMaxPooling2D\nimport openslide\nfrom openslide import OpenSlide\nimport cv2 ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-09-18T01:38:59.804906Z","iopub.execute_input":"2022-09-18T01:38:59.805662Z","iopub.status.idle":"2022-09-18T01:39:07.547426Z","shell.execute_reply.started":"2022-09-18T01:38:59.805615Z","shell.execute_reply":"2022-09-18T01:39:07.546085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('../input/mayo-clinic-strip-ai/train.csv')\ntest_df  = pd.read_csv('../input/mayo-clinic-strip-ai/test.csv')","metadata":{"execution":{"iopub.status.busy":"2022-09-18T01:39:07.548840Z","iopub.execute_input":"2022-09-18T01:39:07.549492Z","iopub.status.idle":"2022-09-18T01:39:07.576079Z","shell.execute_reply.started":"2022-09-18T01:39:07.549455Z","shell.execute_reply":"2022-09-18T01:39:07.574780Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-09-18T01:39:07.578940Z","iopub.execute_input":"2022-09-18T01:39:07.581100Z","iopub.status.idle":"2022-09-18T01:39:07.601806Z","shell.execute_reply.started":"2022-09-18T01:39:07.581054Z","shell.execute_reply":"2022-09-18T01:39:07.600633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[\"file_path\"] = train_df[\"image_id\"].apply(lambda x: \"../input/mayo-clinic-strip-ai/train/\" + x + \".tif\")\ntest_df[\"file_path\"]  = test_df[\"image_id\"].apply(lambda x: \"../input/mayo-clinic-strip-ai/test/\" + x + \".tif\")","metadata":{"execution":{"iopub.status.busy":"2022-09-18T01:39:07.603796Z","iopub.execute_input":"2022-09-18T01:39:07.604628Z","iopub.status.idle":"2022-09-18T01:39:07.616730Z","shell.execute_reply.started":"2022-09-18T01:39:07.604581Z","shell.execute_reply":"2022-09-18T01:39:07.615353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[\"target\"] = train_df[\"label\"].apply(lambda x : 1 if x==\"CE\" else 0)","metadata":{"execution":{"iopub.status.busy":"2022-09-18T01:39:07.618608Z","iopub.execute_input":"2022-09-18T01:39:07.619554Z","iopub.status.idle":"2022-09-18T01:39:07.629813Z","shell.execute_reply.started":"2022-09-18T01:39:07.619509Z","shell.execute_reply":"2022-09-18T01:39:07.628907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-09-18T01:39:07.631531Z","iopub.execute_input":"2022-09-18T01:39:07.631999Z","iopub.status.idle":"2022-09-18T01:39:07.647728Z","shell.execute_reply.started":"2022-09-18T01:39:07.631956Z","shell.execute_reply":"2022-09-18T01:39:07.646201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nimport cv2\nfrom PIL import Image\nimport tifffile as tifi\nj = 4\nsample_train = train_df[j:j+1]\n\nimg = cv2.imread(sample_train.loc[j, \"file_path\"])\nprint('The size of the image is' + str(img.shape))\nplt.figure(figsize=(8, 8))\nplt.imshow(img)\nplt.show()  ","metadata":{"execution":{"iopub.status.busy":"2022-09-18T01:43:08.382308Z","iopub.execute_input":"2022-09-18T01:43:08.382716Z","iopub.status.idle":"2022-09-18T01:43:17.993556Z","shell.execute_reply.started":"2022-09-18T01:43:08.382686Z","shell.execute_reply":"2022-09-18T01:43:17.992607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_resized = tf.image.resize(img, (512, 512))\nprint('The size of the image is' + str(image_resized.shape))\nplt.figure(figsize=(8, 8))\nplt.imshow(image_resized)\nplt.show()  ","metadata":{"execution":{"iopub.status.busy":"2022-09-11T23:26:02.727168Z","iopub.execute_input":"2022-09-11T23:26:02.728199Z","iopub.status.idle":"2022-09-11T23:26:03.308739Z","shell.execute_reply.started":"2022-09-11T23:26:02.728162Z","shell.execute_reply":"2022-09-11T23:26:03.307426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nsample_train = train_df[:4]\n\nfor i in range(1):\n    slide = OpenSlide(sample_train.loc[i, \"file_path\"])\n    region = (0, 0)\n    size = (20000, 20000)\n    region = slide.read_region(region, 0, size)\n    plt.figure(figsize=(8, 8))\n    plt.imshow(region)","metadata":{"execution":{"iopub.status.busy":"2022-09-18T01:52:25.406134Z","iopub.execute_input":"2022-09-18T01:52:25.408484Z","iopub.status.idle":"2022-09-18T01:54:09.436184Z","shell.execute_reply.started":"2022-09-18T01:52:25.408429Z","shell.execute_reply":"2022-09-18T01:54:09.434777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ndef preprocess(image_path):\n    slide=OpenSlide(image_path)\n    region= (0,0)    \n    size  = (20000, 20000)\n    image = slide.read_region(region, 0, size)\n    #print('imgae shape is' + str(image.size))\n    image = tf.image.resize(image, (224, 224),method=tf.image.ResizeMethod.LANCZOS5)\n    image = np.array(image) / 255.0 # Normalization\n    #image = np.array(image)\n    return image\n\nx_train=[]\n# num_img = 10\n# counter = 0\nfor i in tqdm(train_df['file_path']):\n    x1=preprocess(i)\n    #print(x1.shape)\n    x_train.append(x1[:,:,0:3]) # Channel four is useless\n#     counter += 1\n#     if (counter == num_img):\n#         break\n    ","metadata":{"execution":{"iopub.status.busy":"2022-09-06T05:00:48.270359Z","iopub.execute_input":"2022-09-06T05:00:48.271195Z","iopub.status.idle":"2022-09-06T05:09:25.511711Z","shell.execute_reply.started":"2022-09-06T05:00:48.271161Z","shell.execute_reply":"2022-09-06T05:09:25.510626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nFeature Extraction is performed by ResNet50 pretrained on imagenet weights. \nInput size is 224 x 224.\n'''\n\nfeature_extractor = tf.keras.applications.resnet.ResNet50(input_shape=(224, 224, 3),\n                                           include_top=False,\n                                           weights='imagenet')\n# freeze the layers\n# for layer in feature_extractor.layers:\n#   layer.trainable = False\n\n'''\nDefines final dense layers and subsequent softmax layer for classification.\n'''\nx = tf.keras.layers.GlobalAveragePooling2D()(feature_extractor.output)\n# Flatten the output layer to 1 dimension\nx = layers.Flatten()(x)\n# Add a fully connected layer with 1,024 hidden units and ReLU activation\nx = layers.Dropout(0.5)(x)\nx = layers.Dense(128, activation='relu')(x)\nx = layers.Dropout(0.5)(x)\nx = layers.Dense(64, activation='relu')(x)\nx = layers.Dropout(0.5)(x)\n# Add a final sigmoid layer for classification\nx = layers.Dense(1)(x)\n\nmodel = tf.keras.Model(feature_extractor.input, x)\n\nmodel.compile(\n      loss = tf.keras.losses.MeanSquaredError(),    \n      metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"rmse\"), tf.keras.metrics.BinaryAccuracy(name=\"accuracy\")],\n      optimizer = tf.keras.optimizers.Adam(1e-3))\n\n# model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-09-18T01:45:43.146507Z","iopub.execute_input":"2022-09-18T01:45:43.146984Z","iopub.status.idle":"2022-09-18T01:45:44.913801Z","shell.execute_reply.started":"2022-09-18T01:45:43.146946Z","shell.execute_reply":"2022-09-18T01:45:44.912576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train=np.array(x_train)\n#y_train=train_df['target'][0:num_img]\ny_train=train_df['target']\n\nx_train,x_test,y_train,y_test=train_test_split(x_train,y_train,test_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2022-09-06T05:09:27.259089Z","iopub.execute_input":"2022-09-06T05:09:27.259483Z","iopub.status.idle":"2022-09-06T05:09:27.361854Z","shell.execute_reply.started":"2022-09-06T05:09:27.259449Z","shell.execute_reply":"2022-09-06T05:09:27.360843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# # All images will be rescaled by 1./255\n# train_datagen = ImageDataGenerator(rescale=1/255)\n# validation_datagen = ImageDataGenerator(rescale=1/255)\n\n# # Flow training images in batches of 128 using train_datagen generator\n# train_generator = train_datagen.flow_from_dataframe(\n#         train_df[0:10],  \n#         x_col = 'file_path'.\n#         y_col = 'target'\n#         target_size=(224,224),  # All images will be resized to 224*224\n#         batch_size=32,\n#         # Since you use binary_crossentropy loss, you need binary labels\n#         class_mode='binary')\n\n# # Flow validation images in batches of 128 using validation_datagen generator\n# train_generator = train_datagen.flow_from_dataframe(\n#         train_df[10:20],  # This is the source directory for training images\n#         x_col = 'file_path'.\n#         y_col = 'target'\n#         target_size=(224,224),  # All images will be resized to 300x300\n#         batch_size=32,\n#         # Since you use binary_crossentropy loss, you need binary labels\n#         class_mode='binary')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nimport math\nfrom tensorflow.keras.callbacks import LearningRateScheduler, EarlyStopping, Callback, ReduceLROnPlateau, ModelCheckpoint\n\n# def step_decay(epoch):\n#     initial_lrate = 0.001\n#     drop = 0.5\n#     epochs_drop = 20.0\n#     lrate = initial_lrate * math.pow(drop, math.floor((epoch)/epochs_drop))\n#     return lrate\n\n# lrate = LearningRateScheduler(step_decay)\n# earstop = EarlyStopping(monitor = 'val_loss', min_delta = 0, patience = 5)\nlrate = ReduceLROnPlateau(\n    monitor='val_loss',\n    factor=0.5,\n    patience= 20,\n    verbose=1,\n    mode='auto',\n    min_delta=0.0001,\n    cooldown=0,\n    min_lr=0.00000001,\n)\n\nmodel_checkpoint_callback = ModelCheckpoint(\n    filepath='/kaggle/working/resnet50_model.h5',\n    save_weights_only=False,\n    monitor='val_loss',\n    mode='auto',\n    save_best_only=True)\n\nhistory = model.fit(\n    x_train,\n    y_train,\n    epochs = 200,\n    batch_size=32,\n    validation_data = (x_test,y_test),\n    verbose = 1,\n    callbacks = [lrate, model_checkpoint_callback]\n)","metadata":{"execution":{"iopub.status.busy":"2022-09-06T05:14:29.590714Z","iopub.execute_input":"2022-09-06T05:14:29.591181Z","iopub.status.idle":"2022-09-06T05:19:04.778217Z","shell.execute_reply.started":"2022-09-06T05:14:29.591142Z","shell.execute_reply":"2022-09-06T05:19:04.777093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_graphs(history, metric):\n    plt.plot(history.history[metric])\n    plt.plot(history.history[f'val_{metric}'])\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(metric)\n    plt.legend([metric, f'val_{metric}'])\n    plt.savefig(str(metric) +'.png')\n    plt.show()\n    \nplot_graphs(history, \"rmse\")\n#plt.savefig('accuracy.png')\nplot_graphs(history, \"loss\")\n#plt.savefig('loss.png')\nplot_graphs(history, \"accuracy\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-09-06T05:13:46.842128Z","iopub.execute_input":"2022-09-06T05:13:46.843185Z","iopub.status.idle":"2022-09-06T05:13:46.847579Z","shell.execute_reply.started":"2022-09-06T05:13:46.843150Z","shell.execute_reply":"2022-09-06T05:13:46.846721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#del train_df, x_train\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-09-06T05:13:46.848877Z","iopub.execute_input":"2022-09-06T05:13:46.849636Z","iopub.status.idle":"2022-09-06T05:13:47.548833Z","shell.execute_reply.started":"2022-09-06T05:13:46.849602Z","shell.execute_reply":"2022-09-06T05:13:47.547726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = tf.keras.models.load_model('/kaggle/working/resnet50_model.h5')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test1=[]\nfor i in test_df['file_path']:\n    x1=preprocess(i)\n    test1.append(x1[:,:,0:3])\ntest1=np.array(test1)\n\ncnn_pred=model.predict(test1)","metadata":{"execution":{"iopub.status.busy":"2022-09-06T05:13:47.551110Z","iopub.execute_input":"2022-09-06T05:13:47.551478Z","iopub.status.idle":"2022-09-06T05:14:17.102425Z","shell.execute_reply.started":"2022-09-06T05:13:47.551439Z","shell.execute_reply":"2022-09-06T05:14:17.101144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnn_pred","metadata":{"execution":{"iopub.status.busy":"2022-09-06T05:14:17.104495Z","iopub.execute_input":"2022-09-06T05:14:17.104945Z","iopub.status.idle":"2022-09-06T05:14:17.113279Z","shell.execute_reply.started":"2022-09-06T05:14:17.104895Z","shell.execute_reply":"2022-09-06T05:14:17.112268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = pd.DataFrame(test_df[\"patient_id\"].copy())\nsub[\"CE\"] = cnn_pred\nsub[\"CE\"] = sub[\"CE\"].apply(lambda x : 0 if x<0 else x)\nsub[\"CE\"] = sub[\"CE\"].apply(lambda x : 1 if x>1 else x)\nsub[\"LAA\"] = 1- sub[\"CE\"]\n\nsub = sub.groupby(\"patient_id\").mean()\nsub = sub[[\"CE\", \"LAA\"]].round(6).reset_index()\nsub","metadata":{"execution":{"iopub.status.busy":"2022-09-06T05:14:17.115174Z","iopub.execute_input":"2022-09-06T05:14:17.115620Z","iopub.status.idle":"2022-09-06T05:14:17.149150Z","shell.execute_reply.started":"2022-09-06T05:14:17.115587Z","shell.execute_reply":"2022-09-06T05:14:17.148369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.to_csv(\"submission.csv\", index = False)\n!head submission.csv","metadata":{"execution":{"iopub.status.busy":"2022-09-06T05:14:17.150235Z","iopub.execute_input":"2022-09-06T05:14:17.151029Z","iopub.status.idle":"2022-09-06T05:14:18.372944Z","shell.execute_reply.started":"2022-09-06T05:14:17.150984Z","shell.execute_reply":"2022-09-06T05:14:18.371482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}