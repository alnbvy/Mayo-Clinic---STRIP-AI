{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# [MAYO] Simple CNN \nThis competion is to build a prediction model to classify the blood clot origins in ischemic stroke, more in detail, the two major acute ischemic stroke (AIS) etiology subtypes: cardiac and large artery atherosclerosis, using whole slide digital pathology images.  \nEvaluation logic seems quite DIFFICULT, but simply speaking, the aim of this competition is to predict the probability of CE or LAA and hence I'd like to build a simple model using Convolutional Neural Network (CNN) just as starter.\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport gc\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\nfrom tensorflow.keras.layers import GlobalMaxPooling2D\nimport openslide\nfrom openslide import OpenSlide\nimport cv2 ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-09-05T18:17:53.405081Z","iopub.execute_input":"2022-09-05T18:17:53.406485Z","iopub.status.idle":"2022-09-05T18:18:02.979741Z","shell.execute_reply.started":"2022-09-05T18:17:53.406365Z","shell.execute_reply":"2022-09-05T18:18:02.978542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. Read Data\n\nLet's read Train data and Test data. I added the link to image data since image data is stored in separate folder.  \nLabel column (CE or LAA) is the target for prediction, hence this column was changed to 1 or 0.  \n","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv('../input/mayo-clinic-strip-ai/train.csv')\ntest_df  = pd.read_csv('../input/mayo-clinic-strip-ai/test.csv')","metadata":{"execution":{"iopub.status.busy":"2022-09-05T18:18:02.982565Z","iopub.execute_input":"2022-09-05T18:18:02.983446Z","iopub.status.idle":"2022-09-05T18:18:03.012578Z","shell.execute_reply.started":"2022-09-05T18:18:02.983398Z","shell.execute_reply":"2022-09-05T18:18:03.010861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-09-05T18:18:03.015347Z","iopub.execute_input":"2022-09-05T18:18:03.015764Z","iopub.status.idle":"2022-09-05T18:18:03.041597Z","shell.execute_reply.started":"2022-09-05T18:18:03.015730Z","shell.execute_reply":"2022-09-05T18:18:03.040608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[\"file_path\"] = train_df[\"image_id\"].apply(lambda x: \"../input/mayo-clinic-strip-ai/train/\" + x + \".tif\")\ntest_df[\"file_path\"]  = test_df[\"image_id\"].apply(lambda x: \"../input/mayo-clinic-strip-ai/test/\" + x + \".tif\")","metadata":{"execution":{"iopub.status.busy":"2022-09-05T18:18:03.044158Z","iopub.execute_input":"2022-09-05T18:18:03.044669Z","iopub.status.idle":"2022-09-05T18:18:03.059793Z","shell.execute_reply.started":"2022-09-05T18:18:03.044622Z","shell.execute_reply":"2022-09-05T18:18:03.058337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[\"target\"] = train_df[\"label\"].apply(lambda x : 1 if x==\"CE\" else 0)","metadata":{"execution":{"iopub.status.busy":"2022-09-05T18:18:03.061402Z","iopub.execute_input":"2022-09-05T18:18:03.062687Z","iopub.status.idle":"2022-09-05T18:18:03.072735Z","shell.execute_reply.started":"2022-09-05T18:18:03.062646Z","shell.execute_reply":"2022-09-05T18:18:03.071135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-09-05T18:18:03.075279Z","iopub.execute_input":"2022-09-05T18:18:03.075764Z","iopub.status.idle":"2022-09-05T18:18:03.096791Z","shell.execute_reply.started":"2022-09-05T18:18:03.075726Z","shell.execute_reply":"2022-09-05T18:18:03.095395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Quick look at Image of CE and LAA\n\nLet7s take a look at some actual image. First 2 records are CE and the next 2 records are LAA.  \nHmmm... I don't see specific difference between CE and LAA...\n","metadata":{}},{"cell_type":"code","source":"%%time\nimport cv2\nfrom PIL import Image\nimport tifffile as tifi\nj = 4\nsample_train = train_df[j:j+1]\n\nimg = cv2.imread(sample_train.loc[j, \"file_path\"])\nprint('The size of the image is' + str(img.shape))\nplt.figure(figsize=(8, 8))\nplt.imshow(img)\nplt.show()  ","metadata":{"execution":{"iopub.status.busy":"2022-09-05T18:25:14.682010Z","iopub.execute_input":"2022-09-05T18:25:14.682469Z","iopub.status.idle":"2022-09-05T18:25:25.703091Z","shell.execute_reply.started":"2022-09-05T18:25:14.682428Z","shell.execute_reply":"2022-09-05T18:25:25.702008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_resized = tf.image.resize(img, (512, 512),method=tf.image.ResizeMethod.LANCZOS5)\nprint('The size of the image is' + str(image_resized.shape))\nplt.figure(figsize=(8, 8))\nplt.imshow(image_resized)\nplt.show()  ","metadata":{"execution":{"iopub.status.busy":"2022-09-05T18:25:35.709652Z","iopub.execute_input":"2022-09-05T18:25:35.711296Z","iopub.status.idle":"2022-09-05T18:25:36.256344Z","shell.execute_reply.started":"2022-09-05T18:25:35.711245Z","shell.execute_reply":"2022-09-05T18:25:36.254704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nsample_train = train_df[:4]\n\nfor i in range(1):\n    slide = OpenSlide(sample_train.loc[i, \"file_path\"])\n    region = (1000, 1000)\n    size = (6000, 6000)\n    region = slide.read_region(region, 0, size)\n    plt.figure(figsize=(8, 8))\n    plt.imshow(region)","metadata":{"execution":{"iopub.status.busy":"2022-09-05T18:19:44.749716Z","iopub.execute_input":"2022-09-05T18:19:44.750258Z","iopub.status.idle":"2022-09-05T18:19:57.195414Z","shell.execute_reply.started":"2022-09-05T18:19:44.750219Z","shell.execute_reply":"2022-09-05T18:19:57.193952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Image data preprocessing for CNN\n\nImage pixel will be changed to no.array for CNN processing.  \nAs you see in above 2., it takes long time to read each image data by 10,000x10,000 pixel, thus in this notebook 5000x 5000 pixel is fed to CNN, which will lead to less Training data. In this situation, I would like to read as meaningful data as possible and hence image data reading is starting from (1000,1000)position from the very top-left of the image since it seems the top-left potion of each image tends to be blank.  \nAlso, image data is resized to 512x512 in order to avoid memory over error.  \n","metadata":{}},{"cell_type":"code","source":"%%time\ndef preprocess(image_path):\n    slide=OpenSlide(image_path)\n    region= (0,0)    \n    size  = (10000, 10000)\n    image = slide.read_region(region, 0, size)\n    #print('imgae shape is' + str(image.size))\n    image = tf.image.resize(image, (512, 512),method=tf.image.ResizeMethod.LANCZOS5)\n    image = np.array(image) / 255.0 # Normalization\n    return image\n\nx_train=[]\n#num_img = 100\n#counter = 0\n#for i in tqdm(train_df['file_path'],total = num_img):\nfor i in tqdm(train_df['file_path']):\n    x1=preprocess(i)\n    #print(x1.shape)\n    x_train.append(x1[:,:,0:3]) # Channel four is useless\n#     counter += 1\n#     if (counter == num_img):\n#         break\n    ","metadata":{"execution":{"iopub.status.busy":"2022-09-05T16:22:53.845858Z","iopub.execute_input":"2022-09-05T16:22:53.846845Z","iopub.status.idle":"2022-09-05T16:29:20.482882Z","shell.execute_reply.started":"2022-09-05T16:22:53.846805Z","shell.execute_reply":"2022-09-05T16:29:20.481361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. CNN Modelling\n\nConvolutional Neural Network(CNN) is built using Conv2D() method with 3x3 kernel. There will be more room to improve the model by tuning the number of Layers or Filters or adding Pooling layer, etc. This is just a starter.\n","metadata":{}},{"cell_type":"code","source":"model = Sequential()\ninput_shape = (512, 512, 3)\n\nmodel.add(Conv2D(filters=32, kernel_size = (3,3), strides =2, padding = 'same', activation = 'relu', input_shape = input_shape))\n#model.add(tf.keras.layers.MaxPooling2D(2, 2))\nmodel.add(Conv2D(filters=64, kernel_size = (3,3), strides =2, padding = 'same', activation = 'relu'))\n#model.add(Conv2D(filters=128, kernel_size = (3,3), strides =2, padding = 'same', activation = 'relu'))\n#model.add(Conv2D(filters=64, kernel_size = (3,3), strides =2, padding = 'same', activation = 'relu'))\n#model.add(tf.keras.layers.MaxPooling2D(2, 2))\nmodel.add(Conv2D(filters=32, kernel_size = (3,3), strides =2, padding = 'same', activation = 'relu'))\nmodel.add(Flatten())\n#model.add(Dense(128, activation = 'relu'))\nmodel.add(Dense(64, activation = 'relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(32, activation = 'relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(16, activation = 'relu'))\nmodel.add(Dropout(0.5))\n\n\nmodel.add(Dense(1))\n\nmodel.compile(\n    loss = tf.keras.losses.MeanSquaredError(),    \n    metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"rmse\"),tf.keras.metrics.BinaryAccuracy(name=\"accuracy\")],\n    optimizer = tf.keras.optimizers.Adam(1e-4))","metadata":{"execution":{"iopub.status.busy":"2022-09-05T16:29:20.484606Z","iopub.execute_input":"2022-09-05T16:29:20.484971Z","iopub.status.idle":"2022-09-05T16:29:20.630047Z","shell.execute_reply.started":"2022-09-05T16:29:20.484940Z","shell.execute_reply":"2022-09-05T16:29:20.628690Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train=np.array(x_train)\n#y_train=train_df['target'][0:num_img]\ny_train=train_df['target']\n\nx_train,x_test,y_train,y_test=train_test_split(x_train,y_train,test_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2022-09-05T16:29:20.634420Z","iopub.execute_input":"2022-09-05T16:29:20.634812Z","iopub.status.idle":"2022-09-05T16:29:21.164767Z","shell.execute_reply.started":"2022-09-05T16:29:20.634778Z","shell.execute_reply":"2022-09-05T16:29:21.163300Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nimport math\nfrom tensorflow.keras.callbacks import LearningRateScheduler, EarlyStopping, Callback, ReduceLROnPlateau, ModelCheckpoint\n\n# def step_decay(epoch):\n#     initial_lrate = 0.001\n#     drop = 0.5\n#     epochs_drop = 10.0\n#     lrate = initial_lrate * math.pow(drop, math.floor((epoch)/epochs_drop))\n#     return lrate\n\n#lrate = LearningRateScheduler(step_decay)\n# earstop = EarlyStopping(monitor = 'val_loss', min_delta = 0, patience = 5)\nlrate = ReduceLROnPlateau(\n    monitor='val_loss',\n    factor=0.5,\n    patience= 10,\n    verbose=1,\n    mode='auto',\n    min_delta=0.0001,\n    cooldown=0,\n    min_lr=0.00000001,\n)\n\nmodel_checkpoint_callback = ModelCheckpoint(\n    filepath='/kaggle/working',\n    save_weights_only=True,\n    monitor='val_loss',\n    mode='auto',\n    save_best_only=True)\n\nhistory = model.fit(\n    x_train,\n    y_train,\n    epochs = 200,\n    batch_size=32,\n    validation_data = (x_test,y_test),\n    verbose = 1,\n    callbacks = [lrate, model_checkpoint_callback]\n)","metadata":{"execution":{"iopub.status.busy":"2022-09-05T16:29:21.168707Z","iopub.execute_input":"2022-09-05T16:29:21.169678Z","iopub.status.idle":"2022-09-05T16:39:26.007186Z","shell.execute_reply.started":"2022-09-05T16:29:21.169629Z","shell.execute_reply":"2022-09-05T16:39:26.005602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_graphs(history, metric):\n    plt.plot(history.history[metric])\n    plt.plot(history.history[f'val_{metric}'])\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(metric)\n    plt.legend([metric, f'val_{metric}'])\n    plt.savefig(str(metric) +'.png')\n    plt.show()\n    \nplot_graphs(history, \"rmse\")\n#plt.savefig('accuracy.png')\nplot_graphs(history, \"loss\")\n#plt.savefig('loss.png')\nplot_graphs(history, \"accuracy\")","metadata":{"execution":{"iopub.status.busy":"2022-09-05T16:39:26.009374Z","iopub.execute_input":"2022-09-05T16:39:26.009747Z","iopub.status.idle":"2022-09-05T16:39:26.842937Z","shell.execute_reply.started":"2022-09-05T16:39:26.009715Z","shell.execute_reply":"2022-09-05T16:39:26.841430Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#del train_df, x_train\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-09-05T16:39:26.844551Z","iopub.execute_input":"2022-09-05T16:39:26.845775Z","iopub.status.idle":"2022-09-05T16:39:27.099646Z","shell.execute_reply.started":"2022-09-05T16:39:26.845719Z","shell.execute_reply":"2022-09-05T16:39:27.098496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Predict and Submission\n\nThis competition is not binary classification of CE and LAA, and competition owner states that both probability does not have to sum to one(1). However, Knowing that, LAA probability is calculated by 1 - CE probability since I intend to build as simple model as possible.  \n> The submitted probabilities for a given image are not required to sum to one because they are rescaled prior to being scored (each row is divided by the row sum)\n\nFYI, if you sinply put cnn_pred into Sample_submission file, it is no problem on the screen but it will cause an error when you submit it to the competition because the actual test data in submission has multiple image data per each patient. Hence, groupby.mean() is used here to make 1record per each patient.\n","metadata":{}},{"cell_type":"code","source":"test1=[]\nfor i in test_df['file_path']:\n    x1=preprocess(i)\n    test1.append(x1[:,:,0:3])\ntest1=np.array(test1)\n\ncnn_pred=model.predict(test1)","metadata":{"execution":{"iopub.status.busy":"2022-09-05T16:39:27.101128Z","iopub.execute_input":"2022-09-05T16:39:27.101546Z","iopub.status.idle":"2022-09-05T16:39:40.448384Z","shell.execute_reply.started":"2022-09-05T16:39:27.101508Z","shell.execute_reply":"2022-09-05T16:39:40.447068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnn_pred","metadata":{"execution":{"iopub.status.busy":"2022-09-05T16:39:40.450222Z","iopub.execute_input":"2022-09-05T16:39:40.450940Z","iopub.status.idle":"2022-09-05T16:39:40.461117Z","shell.execute_reply.started":"2022-09-05T16:39:40.450899Z","shell.execute_reply":"2022-09-05T16:39:40.459374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = pd.DataFrame(test_df[\"patient_id\"].copy())\nsub[\"CE\"] = cnn_pred\nsub[\"CE\"] = sub[\"CE\"].apply(lambda x : 0 if x<0 else x)\nsub[\"CE\"] = sub[\"CE\"].apply(lambda x : 1 if x>1 else x)\nsub[\"LAA\"] = 1- sub[\"CE\"]\n\nsub = sub.groupby(\"patient_id\").mean()\nsub = sub[[\"CE\", \"LAA\"]].round(6).reset_index()\nsub","metadata":{"execution":{"iopub.status.busy":"2022-09-05T16:39:40.463525Z","iopub.execute_input":"2022-09-05T16:39:40.464972Z","iopub.status.idle":"2022-09-05T16:39:40.491716Z","shell.execute_reply.started":"2022-09-05T16:39:40.464929Z","shell.execute_reply":"2022-09-05T16:39:40.490674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.to_csv(\"submission.csv\", index = False)\n!head submission.csv","metadata":{"execution":{"iopub.status.busy":"2022-09-05T16:39:40.493098Z","iopub.execute_input":"2022-09-05T16:39:40.493679Z","iopub.status.idle":"2022-09-05T16:39:41.715706Z","shell.execute_reply.started":"2022-09-05T16:39:40.493644Z","shell.execute_reply":"2022-09-05T16:39:41.714038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}